{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('train.json', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8263"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>negative</td>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>negative</td>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>negative</td>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973</td>\n",
       "      <td>negative</td>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>negative</td>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id sentiment                                               text\n",
       "0  1945  negative  Досудебное расследование по факту покупки ЕНПФ...\n",
       "1  1957  negative  Медики рассказали о состоянии пострадавшего му...\n",
       "2  1969  negative  Прошел почти год, как железнодорожным оператор...\n",
       "3  1973  negative  По итогам 12 месяцев 2016 года на территории р...\n",
       "4  1975  negative  Астана. 21 ноября. Kazakhstan Today - Агентств..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'neutral', 'positive'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Naive Bayes, CountVectorizer, без предобработки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(data.text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, data.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "clf = nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.74      0.69       369\n",
      "     neutral       0.73      0.62      0.67       979\n",
      "    positive       0.67      0.77      0.72       718\n",
      "\n",
      "    accuracy                           0.69      2066\n",
      "   macro avg       0.68      0.71      0.69      2066\n",
      "weighted avg       0.70      0.69      0.69      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) -//-, с лемматизацией (pymorphy) и правильной токенизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import pymorphy2\n",
    "morph_analyzer = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    words = word_tokenize(text)\n",
    "    lemmas = [morph_analyzer.parse(word)[0].normal_form for word in words] \n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_lemmatized'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.75      0.65       347\n",
      "     neutral       0.76      0.57      0.65      1032\n",
      "    positive       0.63      0.77      0.69       687\n",
      "\n",
      "    accuracy                           0.67      2066\n",
      "   macro avg       0.65      0.70      0.66      2066\n",
      "weighted avg       0.69      0.67      0.67      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bow1 = vec.fit_transform(data.text_lemmatized)\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow1, data.sentiment)\n",
    "\n",
    "clf1 = nb.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, clf1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с) -//-, без пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.72      0.68       369\n",
      "     neutral       0.74      0.63      0.68       978\n",
      "    positive       0.68      0.78      0.72       719\n",
      "\n",
      "    accuracy                           0.70      2066\n",
      "   macro avg       0.69      0.71      0.70      2066\n",
      "weighted avg       0.70      0.70      0.70      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise = list(punctuation)\n",
    "\n",
    "vec1 = CountVectorizer(stop_words=noise)\n",
    "bow2 = vec1.fit_transform(data.text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow2, data.sentiment)\n",
    "\n",
    "clf2 = nb.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, clf2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат немного улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) -//-, без пунктуации и стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.73      0.69       363\n",
      "     neutral       0.76      0.63      0.69       997\n",
      "    positive       0.67      0.79      0.73       706\n",
      "\n",
      "    accuracy                           0.70      2066\n",
      "   macro avg       0.70      0.72      0.70      2066\n",
      "weighted avg       0.71      0.70      0.70      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise1 = stopwords.words('russian') + list(punctuation)\n",
    "\n",
    "vec2 = CountVectorizer(stop_words=noise1)\n",
    "bow3 = vec2.fit_transform(data.text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow3, data.sentiment)\n",
    "\n",
    "clf3 = nb.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, clf3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат почти не изменился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "е) -//-, без пунткуации, стоп-слов, латиницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.70      0.67       365\n",
      "     neutral       0.75      0.61      0.68      1005\n",
      "    positive       0.65      0.79      0.72       696\n",
      "\n",
      "    accuracy                           0.69      2066\n",
      "   macro avg       0.68      0.70      0.69      2066\n",
      "weighted avg       0.70      0.69      0.69      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise2 = list(punctuation) + stopwords.words('russian') + list('abcdefghijklmnopqrstuvwxyz')\n",
    "\n",
    "vec3 = CountVectorizer(stop_words=noise2)\n",
    "bow4 = vec3.fit_transform(data.text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow4, data.sentiment)\n",
    "\n",
    "clf4 = nb.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, clf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат чуть хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) LogReg, CountVectorizer, без пунктуации и стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.58      0.63       383\n",
      "     neutral       0.69      0.71      0.70      1014\n",
      "    positive       0.67      0.71      0.69       669\n",
      "\n",
      "    accuracy                           0.68      2066\n",
      "   macro avg       0.69      0.67      0.67      2066\n",
      "weighted avg       0.69      0.68      0.68      2066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow3, data.sentiment)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "clf5 = lr.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, clf5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дефолтный LogReg работает хуже Наивного Байеса, попробуем подобрать гиперпараметры с помощью GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.009, 0.01, 0.09, 1, 5, 10, 25],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "grid_clf_acc = GridSearchCV(clf5, param_grid = grid_values)\n",
    "grid_clf_acc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дефолтные гиперпараметры соответствуют оптимальным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Naive Bayes, TF-IDF Vectorizer, без пунктуации и стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.08      0.14       358\n",
      "     neutral       0.57      0.96      0.72      1047\n",
      "    positive       0.82      0.34      0.48       661\n",
      "\n",
      "    accuracy                           0.61      2066\n",
      "   macro avg       0.76      0.46      0.45      2066\n",
      "weighted avg       0.71      0.61      0.54      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec4 = TfidfVectorizer(min_df=1, max_df=0.99, stop_words=noise1)\n",
    "bow5 = vec4.fit_transform(data.text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow5, data.sentiment)\n",
    "\n",
    "clf6 = nb.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, clf6.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) kNN, CountVectorizer, без пунктуации и стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.52      0.48       367\n",
      "     neutral       0.60      0.75      0.67       999\n",
      "    positive       0.68      0.37      0.48       700\n",
      "\n",
      "    accuracy                           0.58      2066\n",
      "   macro avg       0.57      0.55      0.54      2066\n",
      "weighted avg       0.60      0.58      0.57      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow3, data.sentiment)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "clf7 = knn.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf7.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) DecisionTree, -//-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.49      0.50       367\n",
      "     neutral       0.61      0.64      0.62       999\n",
      "    positive       0.58      0.54      0.56       700\n",
      "\n",
      "    accuracy                           0.58      2066\n",
      "   macro avg       0.56      0.56      0.56      2066\n",
      "weighted avg       0.58      0.58      0.58      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "clf8 = decision_tree.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf8.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат снова хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучший результат: F-мера = 70**\n",
    "\n",
    "**Модель (clf3): Naive Bayes, CountVectorizer, без пунктуации и стоп-слов**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
